{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\z035793\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\z035793\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\z035793\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50-year-old problem of biology solved by Artif...</td>\n",
       "      <td>DeepMind's AI system 'AlphaFold' has been reco...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft Teams to stop working on Internet Ex...</td>\n",
       "      <td>Microsoft Teams will stop working on Internet ...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hope US won't erect barriers to cooperation: C...</td>\n",
       "      <td>China, in response to reports of US adding Chi...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Global smartphone sales in Q3 falls 5.7% to 36...</td>\n",
       "      <td>The global smartphone sales in the third quart...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>EU hoping Biden will clarify US position on di...</td>\n",
       "      <td>The European Union (EU) is hoping that US Pres...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                       news_headline  \\\n",
       "0  50-year-old problem of biology solved by Artif...   \n",
       "1  Microsoft Teams to stop working on Internet Ex...   \n",
       "2  Hope US won't erect barriers to cooperation: C...   \n",
       "3  Global smartphone sales in Q3 falls 5.7% to 36...   \n",
       "4  EU hoping Biden will clarify US position on di...   \n",
       "\n",
       "                                        news_article news_category  \n",
       "0  DeepMind's AI system 'AlphaFold' has been reco...    technology  \n",
       "1  Microsoft Teams will stop working on Internet ...    technology  \n",
       "2  China, in response to reports of US adding Chi...    technology  \n",
       "3  The global smartphone sales in the third quart...    technology  \n",
       "4  The European Union (EU) is hoping that US Pres...    technology  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your news dataset (Assuming it's in a CSV file)\n",
    "df = pd.read_csv('news_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_category\n",
       "world            2067\n",
       "entertainment    2036\n",
       "sports           1900\n",
       "technology       1791\n",
       "politics         1596\n",
       "science          1437\n",
       "automobile       1293\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"news_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\z035793\\Documents\\others\\side_projects\\news-classifier\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split dataset into training and testing sets\n",
    "X = df['news_article']\n",
    "y = df['news_category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Text preprocessing and vectorization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=word_tokenize)\n",
    "\n",
    "X_train = [' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) if word.isalnum()]) for text in X_train]\n",
    "X_test = [' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) if word.isalnum()]) for text in X_test]\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9245049504950495\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "   automobile       0.86      0.99      0.92       248\n",
      "entertainment       0.95      0.96      0.96       417\n",
      "     politics       0.96      0.96      0.96       302\n",
      "      science       0.95      0.96      0.95       282\n",
      "       sports       0.99      0.93      0.96       390\n",
      "   technology       0.91      0.77      0.83       379\n",
      "        world       0.86      0.94      0.90       406\n",
      "\n",
      "     accuracy                           0.92      2424\n",
      "    macro avg       0.93      0.93      0.93      2424\n",
      " weighted avg       0.93      0.92      0.92      2424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news_classifier_model.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(classifier, 'news_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: world\n"
     ]
    }
   ],
   "source": [
    "# Function to load the model and make predictions\n",
    "def predict_category(input_text):\n",
    "    # Load the saved model\n",
    "    saved_model = joblib.load('news_classifier_model.pkl')\n",
    "    \n",
    "    # Preprocess the input text\n",
    "    input_text = ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(input_text.lower()) if word.isalnum()])\n",
    "    \n",
    "    # Vectorize the input text\n",
    "    input_text_tfidf = vectorizer.transform([input_text])\n",
    "    \n",
    "    # Predict the category\n",
    "    predicted_category = saved_model.predict(input_text_tfidf)[0]\n",
    "    \n",
    "    return predicted_category\n",
    "\n",
    "# Example usage\n",
    "input_text = \"US Federal Communications Commission Chairman Ajit Pai has announced that he will step down from his position on January 20. He will be leaving office on the same day as President-elect Joe Biden's inauguration. Previously, former FCC Chairman Tom Wheeler had left office on 20th January 2017, the day President Donald Trump was sworn in.\"\n",
    "predicted_category = predict_category(input_text)\n",
    "print(\"Predicted Category:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
